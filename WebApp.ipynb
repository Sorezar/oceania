{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ea67bc7e-e69f-4465-86ee-5192e2fbb622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "from collections import deque\n",
    "from werkzeug.utils import secure_filename\n",
    "from flask import Flask, render_template, Response, request, jsonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9f7091a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF_THRESHOLD = 0.6\n",
    "classNames = [\"Bouledogue\",\"Whitetip\",\"Blacktip\"]\n",
    "model = YOLO(\"runs/detect/train16/weights/best.engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "475f35b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(img, results):\n",
    "    detection = False\n",
    "    labels = []\n",
    "    boxes_to_draw = []\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            conf = math.ceil((box.conf[0] * 100)) / 100\n",
    "            if conf > CONF_THRESHOLD:\n",
    "                detection = True\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "                cls = int(box.cls[0])\n",
    "                class_name = classNames[cls]\n",
    "                label = f'{class_name} : {conf*100:.0f}%'\n",
    "                labels.append((x1, y1, label))\n",
    "                boxes_to_draw.append((x1, y1, x2, y2))\n",
    "\n",
    "    # Draw boxes and labels\n",
    "    for (x1, y1, x2, y2) in boxes_to_draw:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 255, 255), 3)\n",
    "\n",
    "    for (x1, y1, label) in labels:\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=1, thickness=2)[0]\n",
    "        c2 = x1 + t_size[0], y1 - t_size[1] - 3\n",
    "        cv2.rectangle(img, (x1, y1), c2, [255, 255, 255], -1, cv2.LINE_AA)\n",
    "        cv2.putText(img, label, (x1, y1 - 2), 0, 1, [122, 0, 0], thickness=1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    return detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4f073d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_detect(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if img is None:\n",
    "        return None\n",
    "    \n",
    "    results = model(img, verbose=False)\n",
    "    make_pred(img, results)\n",
    "                \n",
    "    result_path = image_path.replace('uploads', 'results')\n",
    "    cv2.imwrite(result_path, img)\n",
    "    \n",
    "    return result_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f353a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_detection(path):\n",
    "    \n",
    "    tick = datetime.now()\n",
    "    results = model(path, verbose=False, stream=True, half=True, conf=CONF_THRESHOLD)\n",
    "    tock = datetime.now()\n",
    "    print(f'Inference time: {tock - tick}')\n",
    "    \n",
    "    \n",
    "    res = [r for r in results]\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    \n",
    "    # Config video writer\n",
    "    frame_width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    result_path = path.replace('uploads', 'results')\n",
    "    \n",
    "    # Config segmentation\n",
    "    pre_detection_buffer_length  = int(fps * 1)\n",
    "    post_detection_buffer_length = int(fps * 2)\n",
    "    \n",
    "    frame_idx = 0\n",
    "    no_detection_count = 0\n",
    "    detection_sequence_counter = 0\n",
    "    in_detection_sequence = False\n",
    "    \n",
    "    pre_detection_buffer = deque(maxlen=pre_detection_buffer_length)\n",
    "    \n",
    "    tick = datetime.now()\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, img = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        current   = res[frame_idx]\n",
    "        detection = make_pred(img, current)\n",
    "            \n",
    "        if detection:\n",
    "            if not in_detection_sequence:\n",
    "                in_detection_sequence = True\n",
    "                detection_sequence_counter += 1\n",
    "                video_writer = cv2.VideoWriter(f'static/results/output_{detection_sequence_counter}.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "                \n",
    "                [video_writer.write(buffered_img) for buffered_img in pre_detection_buffer]\n",
    "                pre_detection_buffer.clear()\n",
    "                \n",
    "            no_detection_count = 0\n",
    "            video_writer.write(img)\n",
    "            \n",
    "        else:\n",
    "            no_detection_count += 1\n",
    "            if in_detection_sequence:\n",
    "                if no_detection_count <= post_detection_buffer_length:\n",
    "                    video_writer.write(img)\n",
    "                \n",
    "                else :\n",
    "                    video_writer.release()\n",
    "                    in_detection_sequence = False\n",
    "                    pre_detection_buffer.clear()\n",
    "        \n",
    "        frame_idx += 1\n",
    "        \n",
    "    if in_detection_sequence:\n",
    "        video_writer.release()\n",
    "    \n",
    "    tock = datetime.now()\n",
    "    print(f'Drawing time: {tock - tick}')\n",
    "    \n",
    "    return result_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0280aaf1-69ab-4f25-b0f0-d9c51b68fb72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading runs\\detect\\train16\\weights\\best.engine for TensorRT inference...\n",
      "Inference time: 0:00:00.096482\n",
      "Results saved to \u001b[1mruns\\detect\\predict25\u001b[0m\n",
      "Drawing time: 0:00:49.935372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/May/2024 00:29:47] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__) \n",
    "\n",
    "app.config['UPLOAD_FOLDER'] = 'static/uploads/'\n",
    "app.config['RESULT_FOLDER'] = 'static/results/'\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'mp4', 'avi', 'mov', 'PNG', 'JPG', 'JPEG', 'GIF', 'MP4', 'AVI', 'MOV'}\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def upload_file():\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify(error=\"No selected file\"), 400\n",
    "    \n",
    "    if file and allowed_file(file.filename):\n",
    "        filename = secure_filename(file.filename)\n",
    "        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "        file.save(filepath)\n",
    "        \n",
    "        file_extension = filename.rsplit('.', 1)[1].lower()\n",
    "        if file_extension in ['mp4', 'avi', 'mov', 'MP4', 'AVI', 'MOV']:\n",
    "            result_path = video_detection(filepath)\n",
    "        elif file_extension in ['png', 'jpg', 'jpeg', 'JPG']:\n",
    "            result_path = image_detect(filepath)\n",
    "            \n",
    "        if result_path:\n",
    "            result_filename = os.path.basename(result_path)\n",
    "            return jsonify({'filename': result_filename}), 200\n",
    "    return jsonify({'error': 'Image detection failed'})\n",
    "    \n",
    "@app.route('/webcam')\n",
    "def webcam():\n",
    "    return Response(video_detection(path=0), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/gallery')\n",
    "def gallery():\n",
    "    images = os.listdir('static/results')\n",
    "    images = [image for image in images if image.endswith(('jpg', 'jpeg', 'png', 'gif', 'JPG'))]\n",
    "    return render_template('gallery.html', images=images)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5c12d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
